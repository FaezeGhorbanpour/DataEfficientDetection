{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:06.177946Z",
     "start_time": "2024-12-17T18:17:06.166737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mounts/work/faeze/.cache/hf/'\n",
    "os.environ['HF_HOME'] = '/mounts/work/faeze/.cache/hf/'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/mounts/work/faeze/.cache/hf/'\n",
    "os.environ['TORCH_HUB'] = '/mounts/work/faeze/.cache/torch/'\n",
    "os.environ['TORCH_HOME'] = '/mounts/work/faeze/.cache/torch/'\n",
    "os.environ[\"WANDB_DIR\"] = '/mounts/work/faeze/.cache/wandb/'"
   ],
   "id": "dc6f27063f71fb1b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:11.136505Z",
     "start_time": "2024-12-17T18:17:06.246949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_provider import DataProvider\n",
    "from finetuner import FineTuner, FineTunerConfig"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:11.381303Z",
     "start_time": "2024-12-17T18:17:11.378107Z"
    }
   },
   "cell_type": "code",
   "source": "data_provider_ = DataProvider()",
   "id": "3ba5e89364e192c2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:11.428977Z",
     "start_time": "2024-12-17T18:17:11.422047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "names = ['bas19_es', 'dyn21_en', 'for19_pt', 'fou18_en',\n",
    "                       'has19_hi', 'has20_hi', 'has21_hi', 'ken20_en',\n",
    "                       'ous19_ar', 'ous19_fr', 'san20_it',]\n",
    "\n",
    "datas = [f'baseline_data/{i}' for i in names]\n",
    "languages = [name.split('_')[1] for name in names]\n",
    "languages"
   ],
   "id": "4d42bd732f96c9e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['es', 'en', 'pt', 'en', 'hi', 'hi', 'hi', 'en', 'ar', 'fr', 'it']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:11.975583Z",
     "start_time": "2024-12-17T18:17:11.665684Z"
    }
   },
   "cell_type": "code",
   "source": "datasets = data_provider_.load_datasets(datas, languages)",
   "id": "f898dccaf54679a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/work/faeze/new_miniconda3/envs/2024_9/lib/python3.10/site-packages/datasets/load.py:929: FutureWarning: The repository for baseline_data contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at baseline_data/baseline_data.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:12.036346Z",
     "start_time": "2024-12-17T18:17:12.032316Z"
    }
   },
   "cell_type": "code",
   "source": "datasets[5]",
   "id": "5b1fb19fa2855706",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'baseline_data/dyn21_en',\n",
       " 'split': 'test',\n",
       " 'data': Dataset({\n",
       "     features: ['id', 'text', 'label'],\n",
       "     num_rows: 2000\n",
       " }),\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:12.304206Z",
     "start_time": "2024-12-17T18:17:12.300642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = datasets[0]['data']\n",
    "eval_data = datasets[1]['data']\n",
    "test_data = datasets[2]['data']"
   ],
   "id": "e1aa8daf76648217",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:12.367125Z",
     "start_time": "2024-12-17T18:17:12.364397Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b081d7fb2f87ccbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:12.431227Z",
     "start_time": "2024-12-17T18:17:12.428493Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "27f93fd294af98c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:47.469851Z",
     "start_time": "2024-12-17T18:17:47.465935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "config = FineTunerConfig(\n",
    "        model_name=\"google/mt5-base\",\n",
    "        fine_tune_method=\"lora\",\n",
    "        num_labels=2,  # Binary classification (Hate Speech detection)\n",
    "        learning_rate=5e-5,\n",
    "        epochs=3,\n",
    "        batch_size=16,\n",
    "    # peft_config={\"lora_rank\": 4}\n",
    "    )"
   ],
   "id": "a8477676d4da1438",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:53.885837Z",
     "start_time": "2024-12-17T18:17:51.169170Z"
    }
   },
   "cell_type": "code",
   "source": "fine_tuner = FineTuner(config)",
   "id": "576eefc2f5830ab2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MT5ForSequenceClassification were not initialized from the model checkpoint at google/mt5-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:57.882941Z",
     "start_time": "2024-12-17T18:17:57.321539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = fine_tuner.prepare_data(train_data)\n",
    "eval_dataset = fine_tuner.prepare_data(eval_data)\n",
    "test_dataset = fine_tuner.prepare_data(test_data)"
   ],
   "id": "f19ac87f14300225",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:20:29.276617Z",
     "start_time": "2024-12-17T18:17:58.693383Z"
    }
   },
   "cell_type": "code",
   "source": "fine_tuner.train(train_dataset, eval_dataset)",
   "id": "fe7daa108014765e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mparvaz\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/mounts/work/faeze/.cache/wandb/wandb/run-20241217_191803-0jfcqr6d</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/parvaz/huggingface/runs/0jfcqr6d' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/parvaz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/parvaz/huggingface' target=\"_blank\">https://wandb.ai/parvaz/huggingface</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/parvaz/huggingface/runs/0jfcqr6d' target=\"_blank\">https://wandb.ai/parvaz/huggingface/runs/0jfcqr6d</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/99 02:06 < 04:17, 0.25 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"The `metric_for_best_model` training argument is set to 'eval_loss', which is not found in the evaluation metrics. The available evaluation metrics are: []. Consider changing the `metric_for_best_model` via the TrainingArguments.\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2900\u001B[0m, in \u001B[0;36mTrainer._save_checkpoint\u001B[0;34m(self, model, trial, metrics)\u001B[0m\n\u001B[1;32m   2899\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 2900\u001B[0m     metric_value \u001B[38;5;241m=\u001B[39m \u001B[43mmetrics\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmetric_to_check\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m   2901\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'eval_loss'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mfine_tuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/tmp/pycharm_project_732/finetuner.py:143\u001B[0m, in \u001B[0;36mFineTuner.train\u001B[0;34m(self, train_data, eval_data, output_dir)\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;66;03m# Use class weights in the loss function\u001B[39;00m\n\u001B[1;32m    142\u001B[0m trainer\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mlabel_smoothing_factor \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m  \u001B[38;5;66;03m# Standard loss function (use weights in the trainer)\u001B[39;00m\n\u001B[0;32m--> 143\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1938\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1936\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1937\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1938\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1939\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1940\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1941\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1942\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1943\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2376\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2373\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_training_stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   2375\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_epoch_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m-> 2376\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2378\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m DebugOption\u001B[38;5;241m.\u001B[39mTPU_METRICS_DEBUG \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdebug:\n\u001B[1;32m   2379\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_torch_xla_available():\n\u001B[1;32m   2380\u001B[0m         \u001B[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2807\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2804\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluate(trial, ignore_keys_for_eval)\n\u001B[1;32m   2806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_save:\n\u001B[0;32m-> 2807\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2808\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_save(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2902\u001B[0m, in \u001B[0;36mTrainer._save_checkpoint\u001B[0;34m(self, model, trial, metrics)\u001B[0m\n\u001B[1;32m   2900\u001B[0m     metric_value \u001B[38;5;241m=\u001B[39m metrics[metric_to_check]\n\u001B[1;32m   2901\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m-> 2902\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[1;32m   2903\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `metric_for_best_model` training argument is set to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_to_check\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, which is not found in the evaluation metrics. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2904\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe available evaluation metrics are: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(metrics\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Consider changing the `metric_for_best_model` via the TrainingArguments.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2905\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n\u001B[1;32m   2907\u001B[0m operator \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mgreater \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgreater_is_better \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39mless\n\u001B[1;32m   2908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2909\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mbest_metric \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2910\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mbest_model_checkpoint \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2911\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m operator(metric_value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mbest_metric)\n\u001B[1;32m   2912\u001B[0m ):\n",
      "\u001B[0;31mKeyError\u001B[0m: \"The `metric_for_best_model` training argument is set to 'eval_loss', which is not found in the evaluation metrics. The available evaluation metrics are: []. Consider changing the `metric_for_best_model` via the TrainingArguments.\""
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:17:31.804136405Z",
     "start_time": "2024-12-17T17:34:31.932245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = fine_tuner.predict(test_dataset)\n",
    "results = fine_tuner.compute_metrics(prediction)\n",
    "print(results)"
   ],
   "id": "71ef10423348daff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.758, 'f1-macro': 0.715371469635899, 'precision': 0.7543940303940304, 'recall': 0.758, 'f1-weighted': 0.7559071264162328}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:20:29.361095485Z",
     "start_time": "2024-12-17T16:54:27.715296Z"
    }
   },
   "cell_type": "code",
   "source": "{'accuracy': 0.782, 'f1-macro': 0.7790265816831281, 'precision': 0.7872806227483272, 'recall': 0.782, 'f1-weighted': 0.7831278483270894}",
   "id": "dbbeaffac57317c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "{'accuracy': 0.758, 'f1-macro': 0.715371469635899, 'precision': 0.7543940303940304, 'recall': 0.758, 'f1-weighted': 0.7559071264162328}",
   "id": "cd2ab993a4db9d54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
