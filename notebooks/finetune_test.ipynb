{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:00:42.031046Z",
     "start_time": "2024-12-24T16:00:42.018924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mounts/work/faeze/.cache/hf/'\n",
    "os.environ['HF_HOME'] = '/mounts/work/faeze/.cache/hf/'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/mounts/work/faeze/.cache/hf/'\n",
    "os.environ['TORCH_HUB'] = '/mounts/work/faeze/.cache/torch/'\n",
    "os.environ['TORCH_HOME'] = '/mounts/work/faeze/.cache/torch/'\n",
    "os.environ[\"WANDB_DIR\"] = '/mounts/work/faeze/.cache/wandb/'"
   ],
   "id": "dc6f27063f71fb1b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-24T16:02:11.183773Z",
     "start_time": "2024-12-24T16:00:42.101446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_provider import DataProvider\n",
    "from finetuner import FineTuner\n",
    "from main import FineTunerArguments"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:02:11.393318Z",
     "start_time": "2024-12-24T16:02:11.390074Z"
    }
   },
   "cell_type": "code",
   "source": "data_provider_ = DataProvider()",
   "id": "3ba5e89364e192c2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:03:23.528327Z",
     "start_time": "2024-12-24T16:03:23.520802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datas = ['bas19_es', 'dyn21_en', 'for19_pt', 'fou18_en', 'has21_hi', 'ken20_en',\n",
    "                       'ous19_ar', 'ous19_fr', 'san20_it',]\n",
    "\n",
    "# datas = [f'baseline_data/{i}' for i in names]\n",
    "languages = [name.split('_')[1] for name in names]\n",
    "languages"
   ],
   "id": "4d42bd732f96c9e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['es', 'en', 'pt', 'en', 'hi', 'en', 'ar', 'fr', 'it']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:03:57.421573Z",
     "start_time": "2024-12-24T16:03:27.114800Z"
    }
   },
   "cell_type": "code",
   "source": "datasets = data_provider_.load_datasets(datas, languages)",
   "id": "f898dccaf54679a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65a413570ee041eea5d20d57df3f9fbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ccbadd09fb44e1a9ebd3c30f5f46f53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7457b36918e74b0e86abf130ddaf348e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a1a732893274b988aa3e3b077e07f97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid row: ['based. SCOTUS took a shit on the constitution and this shithead will be president for 3 days and you have kamala puppet for 5 terms in a row.']\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: [\"( holdin' jewish gals severed head )\"]\n",
      "Skipping invalid row: ['France still has the islands of Saint Pierre and Miquelon off Newfoundland far from Europe.']\n",
      "Skipping invalid row: ['not sure of your argument but most people dont hate tourists worldwide. Most places that have lots of tourists are actually very friendly to tourists. The places where ']\n",
      "Skipping invalid row: ['That’s the problem with islam: it is completely soleless.']\n",
      "Skipping invalid row: ['Islam has absolutely no sole.']\n",
      "Skipping invalid row: ['And Muslims have no soul.']\n",
      "Skipping invalid row: ['trannies are generally pussies! Tonight I called three of them dickheads to their face. All I got out of them was ']\n",
      "Skipping invalid row: ['There is only one immigrants to this country that have ever posed a threat as large as OP is making these refugees out to be: white people.']\n",
      "Skipping invalid row: [\"My friend married an asian woman despite my warnings. Guess what? They now have a hapa child. Utterly disgusting. I haven't talked to him ever since that mischling was born. \"]\n",
      "Skipping invalid row: ['The oldest known Briton was actually white. The people who formed my ancestors culture and faith were white. Its ']\n",
      "Skipping invalid row: ['Sure!! Bring them all back so they can get some freebies and some rest and recovery for their next jihadi attack... after all what‚Äôs a good useful idiot supposed to do In the meantime? how about bring the persucted Christians out of the Middle East war zone oh wait they don‚Äôt count. Only care about the murdering Moslems after all']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['Last chance from our almighty god Allah to wake up from deep sleep we 90%  poor oppressed abandoned Indians are in sleep.']\n",
      "Skipping invalid row: ['Allah always plans good. He has choosen the farmers so the farmers equal God sent. Now India must choose Good over bad']\n",
      "Skipping invalid row: ['They need a new testament or reformation.']\n",
      "Skipping invalid row: ['i lived in London and it was sh1te']\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: ['i dont get it Do you also go on about archaeologists that break into ancient mausoleums that went into great lengths to keep them out for religious reasons? Or about those ']\n",
      "Skipping invalid row: ['The moderate Muslim']\n",
      "Skipping invalid row: ['The moderate crocodile.']\n",
      "Skipping invalid row: ['The moderate cobra snake.']\n",
      "Skipping invalid row: ['The moderate shark.']\n",
      "Skipping invalid row: ['Chilling.']\n",
      "Skipping invalid row: ['But absolutely not surprising from a religion of pure evil.']\n",
      "Skipping invalid row: ['May God guide and help Israel and her people always against the Muslim aggressors…']\n",
      "Skipping invalid row: [\"Maybe if she had a more diverse friendship group and fewer racist family members she would know. I enjoy learning about my friend's religions/cultures.\"]\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: [\"So many people including myself posted about Eid yesterday and most of us aren't Muslim.\"]\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['this is so true slavery in the Arab world is literally why anti-Blackness racism overt in the Arab world. Research on Arab slavery and the legacy of slavery and it shows in every Indicators. Let’s ask Black People']\n",
      "Skipping invalid row: ['Oh Jesus christ man. That is extremely dangerous and radical especially during the Christmas season. Of course there are some good guys among refugees but there are troublemakers as well. A proper ']\n",
      "Skipping invalid row: [\"Wow that's damn amazing of her. It reminds me of white people I know with blm in their bio who I've seen treat \"]\n",
      "Skipping invalid row: ['The dead muslims are for sure celebrated as martyrs for defending their']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['bear in mind This country is crumbling all around us and all these stupid people can think about is throwing a temper']\n",
      "Skipping invalid row: ['I guess this is what happens when you allow an unfettered Muslim invasion of Germany! Thank you Chancellor Merkel!']\n",
      "Skipping invalid row: ['The German citizens deserve so much better! Hopefully there is still time to prevent this madness!']\n",
      "Skipping invalid row: ['I hope that incompetent cunt beheads people']\n",
      "Skipping invalid row: ['I wish this incompetent Crip would just drop dead.']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: [\"there won't be any normal games next year. They'll be back for 2024 but in a new look version. The public will be\"]\n",
      "Skipping invalid row: [\"boat niggers tend to live in their own bubbles and these things don't affect them till they hit \"]\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['I seriously have a question about those people that are seeking asylum. As we all know people that are refugees rarely have the ability to obtain a travel document by legal means so the reality of ']\n",
      "Skipping invalid row: ['i actually  think the argument here is why she didn’t go private years ago instead of wasting NHS resources at a time when we’re more stretched than ever?']\n",
      "Skipping invalid row: ['He is a pig God']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['i dont get it. Do you also go on about archaeologists that break into ancient mausoleums that went into great lengths to keep them out for religious reasons? Or about those ']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['California Muslim: “I will assassinate your pastor in the name of Allah. I will burn down Christian churches”']\n",
      "Skipping invalid row: ['Lebanon my friend used to be perfect and it was more stunning and way better then']\n",
      "Skipping invalid row: ['Monaco you are at the beach 30 min later you are on the ski slope with killer ']\n",
      "Skipping invalid row: ['Last chance from their almighty god Allah to wake up from deep sleep the 90%  poor oppressed abandoned Indians are in sleep.']\n",
      "Skipping invalid row: ['Allah always plans terrorism. He has choosen the farmers so the farmers equal God sent. Now India must choose Good over bad']\n",
      "Skipping invalid row: ['i lived in London and it was sh1te']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: [\"My friend married an consrvative Republican woman despite my warnings. Guess what? They now have a child who plays with guns. Utterly disgusting. I haven't talked to him ever since that Nazi was born. \"]\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['They had to start a war to bring the great Germany plummeting.... when they where in that ']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['Q. What is the UN doing about this?']\n",
      "Skipping invalid row: [\"neanderthals couldn't breed with us and produce viable offspring. the only instance when this was possible was a female human with a male neanderthal having female kids\"]\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['Marine Le Pen would never have allowed this to happen.']\n",
      "Skipping invalid row: ['The court decision in the UK about immigration should be a wake-up call to everyone who think British gov is their fucking ']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: [\"there's no place like home however I am so glad I moved back to England as nowadays \"]\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['Exactly. There are already 2 shows dedicated to this type of awful television. Benefit street and Costa de dole.']\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: [\"She is a spoilt self entitled bitch and this video shows it perfectly and clearly. It's not cute hun to speak to your \"]\n",
      "Skipping invalid row: ['Q. What is the UN doing about this?']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['Filthy muslims simply the proxy army of the jew to be used on Whites and Christians.']\n",
      "Skipping invalid row: [\"kids are capricious. That's all you have to know and it's why they can't be trusted. They say they love one thing\"]\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['excuse me but They are mostly all single Muslim males who bypassed many safe countries. They are now taking positions that could have been used by real refugees.  Hegira or Hijra - means Rewarded in ']\n",
      "Skipping invalid row: [\"It's a fact that your kids are happiest when complaining. That's why you should just listen to them instead of offering solutions as \"]\n",
      "Skipping invalid row: ['Filthy rats on the subway simply the proxy army of the gov to be used on New York inhabitants.']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['The communist revolution that killed over 50 million russians......was carried out by the']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['I wish this incompetent cunt would just drop dead.']\n",
      "Skipping invalid row: [\"Companies: Let's talk about race and religion.\"]\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: ['(China: *Commits ethnic cleansing*)']\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: [\"neanderthals couldn't breed with us and produce viable offspring. the only instance when this was possible was a female human with a male neanderthal having female kids\"]\n",
      "Skipping invalid row: ['the bible describes the niggas as being much darker in skin color - and whites as far more']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: [\"To answer that I need you to first realise that Islam isn't just one interpretation but has a large range of individual people and interpretations.\"]\n",
      "Skipping invalid row: [\"It's proper Muslims pushing back against Muslim extemists.\"]\n",
      "Skipping invalid row: ['Allah is a pig God']\n",
      "Skipping invalid row: ['The moderate paedophile']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['The moderate crocodile.']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['The moderate cobra snake.']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['The moderate shark.']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['There is only one immigrants to this country that have ever posed a threat as large as OP is making these refugees out to be: jewish people.']\n",
      "Skipping invalid row: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "016a53c1bb5c40a09a7303c72cae976a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid row: [\"That's the problem with masculinity: it is completely soleless.\"]\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['Masculinity has absolutely no sole.']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['And Men have no soul.']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['Some GB athletes possess a level of awareness that enables them to resist their genetic impulses. ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d793aefc44e24f4c9efee087e54a398d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid row: ['The affair was star-studded with every famous/important person you could imagine. ']\n",
      "Skipping invalid row: []\n",
      "Skipping invalid row: ['This s great! I remeber My ex-in-laws fled Iran to provide their sons with a better life. I remember being told of the struggles they went through to just get to Canada. This right here makes me so proud to be ']\n",
      "Skipping invalid row: ['@user']\n",
      "Skipping invalid row: ['let me tell you no one actually stops you from entering Mecca to check if you’re muslim. I’ve been there multiple times (I’m a Muslim) and there isn’t like ']\n",
      "Skipping invalid row: [\"Pakistan isn't white lol. Plus I often see pakis claim to be white by cherrypicking a few Afghan/Pashtun tribesmen. Even most Afghans don't look like that. \"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "669a3bca01ab4782b81c0049e89e364b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "089ee204ca384b0295089cc3ed98028d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a640a0204231484797e6d563c30d2b69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faeb7a73a7984c48b39a4af0b56be765"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ab9a050df1040788e3a594f709ba96a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "568a2d599abb4a9e91c3d8dacc75afe7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84ec46afb7c94639a922a477ab89c04b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a4e5e2c972543ca9cd71cc29b2a46bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc7528398d7b4c3ca4bb7204510830f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dd912e76b744cb8a1da008b229e5ad5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ddf18a539254ad98c99325eed07f044"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcfe607def1a4b709f66861bcd52f021"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ad10ef2695148d095afd834eba65ba7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c21793604c7497ab196e4d94ba3dcd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "854260b3adb64a599dec59f24ce16324"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01f4219b92c64a8ea3cb8b2d5e88ccc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20588d4b019d4954afe882e40e423216"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4062653106db4c8c8570bc9ae46a4384"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22fbee1d3f6f493ea89812aad1e1d050"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfb8e101a6b040a0bbe7a05e846a4cc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eff949ae8587482a9ef308837468fc35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:03:57.515661Z",
     "start_time": "2024-12-24T16:03:57.508181Z"
    }
   },
   "cell_type": "code",
   "source": "datasets[5]",
   "id": "5b1fb19fa2855706",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ken20_en',\n",
       " 'data': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 20692\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 2000\n",
       "     })\n",
       " }),\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:03:57.596967Z",
     "start_time": "2024-12-24T16:03:57.592507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = datasets[0]['data']['train']\n",
    "eval_data = datasets[0]['data']['validation']\n",
    "test_data = datasets[0]['data']['test']"
   ],
   "id": "e1aa8daf76648217",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:03:57.665473Z",
     "start_time": "2024-12-24T16:03:57.657480Z"
    }
   },
   "cell_type": "code",
   "source": "datasets",
   "id": "b081d7fb2f87ccbe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'bas19_es',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 4100\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 500\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2000\n",
       "      })\n",
       "  }),\n",
       "  'language': 'es'},\n",
       " {'name': 'dyn21_en',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 38644\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 500\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2000\n",
       "      })\n",
       "  }),\n",
       "  'language': 'en'},\n",
       " {'name': 'for19_pt',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 3170\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 500\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2000\n",
       "      })\n",
       "  }),\n",
       "  'language': 'pt'},\n",
       " {'name': 'fou18_en',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 20065\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 500\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2000\n",
       "      })\n",
       "  }),\n",
       "  'language': 'en'},\n",
       " {'name': 'has21_hi',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2094\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 500\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2000\n",
       "      })\n",
       "  }),\n",
       "  'language': 'hi'},\n",
       " {'name': 'ken20_en',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 20692\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 500\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2000\n",
       "      })\n",
       "  }),\n",
       "  'language': 'en'},\n",
       " {'name': 'ous19_ar',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2053\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 300\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 1000\n",
       "      })\n",
       "  }),\n",
       "  'language': 'ar'},\n",
       " {'name': 'ous19_fr',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2014\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 500\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 1500\n",
       "      })\n",
       "  }),\n",
       "  'language': 'fr'},\n",
       " {'name': 'san20_it',\n",
       "  'data': DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 5600\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 500\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['id', 'text', 'label'],\n",
       "          num_rows: 2000\n",
       "      })\n",
       "  }),\n",
       "  'language': 'it'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:03:57.783740Z",
     "start_time": "2024-12-24T16:03:57.780794Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "27f93fd294af98c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:03:58.285717Z",
     "start_time": "2024-12-24T16:03:57.859546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "config = FineTunerArguments(\n",
    "        finetuner_model_name_or_path=\"/mounts/work/faeze/data_efficient_hate/models/finetuner/mdeberta-default/dyn21_en-20000/rs5/checkpoint-11250\",\n",
    "        finetuner_tokenizer_name_or_path=\"microsoft/mdeberta-v3-base\",\n",
    "        fine_tune_method=\"default\",\n",
    "        num_labels=2,  # Binary classification (Hate Speech detection)\n",
    "        learning_rate=5e-5,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        output_dir=\"/mounts/work/faeze/data_efficient_hate/models/finetuner/mdeberta-dyn21/bas19_es-2000/rs1/\",\n",
    "    # peft_config={\"lora_rank\": 4}\n",
    "    )"
   ],
   "id": "a8477676d4da1438",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T16:06:29.482816Z",
     "start_time": "2024-12-24T16:06:17.780177Z"
    }
   },
   "cell_type": "code",
   "source": "fine_tuner = FineTuner(config)",
   "id": "576eefc2f5830ab2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "747cdcaa734e4f4aae872f538abf33f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b134c0de3c85467088f1b7385e451cfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06cd8d1e50f843f288cb6a2e8bd20906"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T15:44:54.568577736Z",
     "start_time": "2024-12-19T14:38:42.422063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = fine_tuner.prepare_data(train_data)\n",
    "eval_dataset = fine_tuner.prepare_data(eval_data)\n",
    "test_dataset = fine_tuner.prepare_data(test_data)"
   ],
   "id": "f19ac87f14300225",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T14:46:49.341183Z",
     "start_time": "2024-12-19T14:38:43.965321Z"
    }
   },
   "cell_type": "code",
   "source": "fine_tuner.train(train_dataset, eval_dataset)",
   "id": "fe7daa108014765e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [165/165 08:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.669700</td>\n",
       "      <td>0.565356</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.671097</td>\n",
       "      <td>0.691927</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.691792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.817341</td>\n",
       "      <td>0.837512</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.829477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>0.387590</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.815761</td>\n",
       "      <td>0.830115</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.827029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.426065</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.821995</td>\n",
       "      <td>0.837824</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.827869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.384766</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>0.844757</td>\n",
       "      <td>0.852296</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>0.852134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T14:37:32.319676Z",
     "start_time": "2024-12-19T14:36:51.626948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = fine_tuner.predict(test_dataset)\n",
    "results = fine_tuner.compute_metrics(prediction)\n",
    "print(results)"
   ],
   "id": "71ef10423348daff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/faeze/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8015, 'f1-macro': 0.7990011318210826, 'precision': 0.8074411137805951, 'recall': 0.8015, 'f1-weighted': 0.8025869516293944}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T14:37:32.678363Z",
     "start_time": "2024-12-19T14:37:32.459352Z"
    }
   },
   "cell_type": "code",
   "source": "{'accuracy': 0.782, 'f1-macro': 0.7790265816831281, 'precision': 0.7872806227483272, 'recall': 0.782, 'f1-weighted': 0.7831278483270894}",
   "id": "dbbeaffac57317c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.782,\n",
       " 'f1-macro': 0.7790265816831281,\n",
       " 'precision': 0.7872806227483272,\n",
       " 'recall': 0.782,\n",
       " 'f1-weighted': 0.7831278483270894}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T14:37:33.026065Z",
     "start_time": "2024-12-19T14:37:32.800730Z"
    }
   },
   "cell_type": "code",
   "source": "{'accuracy': 0.758, 'f1-macro': 0.715371469635899, 'precision': 0.7543940303940304, 'recall': 0.758, 'f1-weighted': 0.7559071264162328}",
   "id": "cd2ab993a4db9d54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.758,\n",
       " 'f1-macro': 0.715371469635899,\n",
       " 'precision': 0.7543940303940304,\n",
       " 'recall': 0.758,\n",
       " 'f1-weighted': 0.7559071264162328}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
